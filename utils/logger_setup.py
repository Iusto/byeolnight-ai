import logging
import os
from datetime import datetime
from logging.handlers import RotatingFileHandler

def setup_logger():
    """ë¡œê·¸ ì‹œìŠ¤í…œ ì„¤ì •"""
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # ë¡œê±° ì„¤ì •
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (íšŒì „ ë¡œê·¸)
    file_handler = RotatingFileHandler(
        filename=os.path.join(log_dir, "crawler.log"),
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.INFO)
    
    # ì—ëŸ¬ ì „ìš© íŒŒì¼ í•¸ë“¤ëŸ¬
    error_handler = RotatingFileHandler(
        filename=os.path.join(log_dir, "error.log"),
        maxBytes=5*1024*1024,  # 5MB
        backupCount=3,
        encoding='utf-8'
    )
    error_handler.setLevel(logging.ERROR)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # í¬ë§·í„° ì„¤ì •
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    file_handler.setFormatter(formatter)
    error_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    # í•¸ë“¤ëŸ¬ ì¶”ê°€
    logger.addHandler(file_handler)
    logger.addHandler(error_handler)
    logger.addHandler(console_handler)
    
    return logger

def log_crawling_result(crawler_type: str, result: dict):
    """í¬ë¡¤ë§ ê²°ê³¼ ë¡œê·¸ ê¸°ë¡"""
    logger = logging.getLogger(__name__)
    
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    if crawler_type == "news":
        logger.info(f"ğŸ“° [{timestamp}] ë‰´ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ - ì´ {result['total']}ê°œ ì¤‘ {result['success']}ê°œ ì„±ê³µ")
        logger.info(f"ğŸ“° [{timestamp}] ë‰´ìŠ¤ ì†ŒìŠ¤: {', '.join(result['sources'])}")
    elif crawler_type == "observatory":
        logger.info(f"ğŸ›ï¸ [{timestamp}] ì²œë¬¸ëŒ€ ì¼ì • í¬ë¡¤ë§ ì™„ë£Œ - ì´ {result['total_events']}ê°œ ì¤‘ {result['success']}ê°œ ì„±ê³µ")
        logger.info(f"ğŸ›ï¸ [{timestamp}] ì²œë¬¸ëŒ€: {', '.join(result['observatories'])}")
    
    # ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ì—ëŸ¬ ë¡œê·¸ì—ë„ ê¸°ë¡
    if result.get('success', 0) < result.get('total', 0) or result.get('success', 0) < result.get('total_events', 0):
        failed_count = result.get('total', result.get('total_events', 0)) - result.get('success', 0)
        logger.error(f"âŒ [{timestamp}] {crawler_type} í¬ë¡¤ë§ ì¤‘ {failed_count}ê°œ ì‹¤íŒ¨")

def log_duplicate_skip(source: str, title: str, reason: str):
    """ì¤‘ë³µ ì²˜ë¦¬ ë¡œê¹…"""
    logger = logging.getLogger('duplicate')
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    logger.info(f"ğŸ”„ [{timestamp}] [{source}] ì¤‘ë³µ ì²˜ë¦¬: {title[:50]}... - {reason}")

def log_retry_failure(source: str, title: str, attempts: int):
    """ì¬ì‹œë„ ì‹¤íŒ¨ ë¡œê¹…"""
    logger = logging.getLogger(__name__)
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    logger.error(f"âŒ [{timestamp}] [{source}] ìµœì¢… ì‹¤íŒ¨ ({attempts}íšŒ ì‹œë„): {title[:50]}...")

def log_crawling_error(source: str, error: str, url: str = None):
    """í¬ë¡¤ë§ ì—ëŸ¬ ë¡œê¹…"""
    logger = logging.getLogger(__name__)
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    error_msg = f"ğŸš¨ [{timestamp}] [{source}] í¬ë¡¤ë§ ì‹¤íŒ¨: {error}"
    if url:
        error_msg += f" - URL: {url}"
    logger.error(error_msg)