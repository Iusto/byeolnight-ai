import requests
from bs4 import BeautifulSoup
import logging
from datetime import datetime, timedelta
import re
from typing import List, Dict
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
logger = logging.getLogger(__name__)

def crawl_kasi_observatory():
    """í•œêµ­ì²œë¬¸ì—°êµ¬ì› ì²œë¬¸ëŒ€ ê²¬í•™ ì¼ì •"""
    try:
        url = "https://www.kasi.re.kr/kor/pageView/174"
        resp = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, verify=False, timeout=10)
        soup = BeautifulSoup(resp.content, "html.parser")
        
        events = []
        # ê²¬í•™ ì¼ì • í…Œì´ë¸”ì—ì„œ ì •ë³´ ì¶”ì¶œ
        for row in soup.select(".board_list tbody tr")[:5]:
            title_elem = row.select_one("td.subject a")
            date_elem = row.select_one("td:nth-child(3)")
            
            if title_elem and date_elem:
                title = title_elem.get_text(strip=True)
                date = date_elem.get_text(strip=True)
                
                events.append({
                    "name": "í•œêµ­ì²œë¬¸ì—°êµ¬ì›",
                    "title": title,
                    "date": date,
                    "location": "ëŒ€ì „ ìœ ì„±êµ¬",
                    "url": f"https://www.kasi.re.kr{title_elem.get('href')}",
                    "type": "ê²¬í•™"
                })
        
        return events
    except Exception as e:
        logger.error(f"KASI ì²œë¬¸ëŒ€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return []

def crawl_seoul_observatory():
    """ì„œìš¸ì‹œë¦½ê³¼í•™ê´€ ì²œë¬¸ëŒ€ í”„ë¡œê·¸ë¨"""
    try:
        url = "https://science.seoul.go.kr/program/list"
        resp = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
        soup = BeautifulSoup(resp.content, "html.parser")
        
        events = []
        for item in soup.select(".program-item")[:3]:
            title_elem = item.select_one(".title")
            date_elem = item.select_one(".date")
            
            if title_elem:
                title = title_elem.get_text(strip=True)
                date = date_elem.get_text(strip=True) if date_elem else "ì¼ì • í™•ì¸ í•„ìš”"
                
                if "ì²œë¬¸" in title or "ë³„" in title or "ìš°ì£¼" in title:
                    events.append({
                        "name": "ì„œìš¸ì‹œë¦½ê³¼í•™ê´€",
                        "title": title,
                        "date": date,
                        "location": "ì„œìš¸ ë…¸ì›êµ¬",
                        "url": url,
                        "type": "ì²´í—˜í”„ë¡œê·¸ë¨"
                    })
        
        return events
    except Exception as e:
        logger.error(f"ì„œìš¸ì‹œë¦½ê³¼í•™ê´€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return []

def crawl_gwacheon_observatory():
    """êµ­ë¦½ê³¼ì²œê³¼í•™ê´€ ì²œë¬¸ëŒ€ í”„ë¡œê·¸ë¨"""
    try:
        # ì‹¤ì œ ì‚¬ì´íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”
        events = [
            {
                "name": "êµ­ë¦½ê³¼ì²œê³¼í•™ê´€",
                "title": "ì²œì²´ê´€ì¸¡êµì‹¤",
                "date": "ë§¤ì£¼ í† ìš”ì¼ 19:00-21:00",
                "location": "ê²½ê¸° ê³¼ì²œì‹œ",
                "url": "https://www.sciencecenter.go.kr",
                "type": "ì •ê¸°í”„ë¡œê·¸ë¨"
            },
            {
                "name": "êµ­ë¦½ê³¼ì²œê³¼í•™ê´€",
                "title": "ê°€ì¡±ì²œë¬¸êµì‹¤",
                "date": "ë§¤ì›” ë‘˜ì§¸, ë„·ì§¸ ì¼ìš”ì¼",
                "location": "ê²½ê¸° ê³¼ì²œì‹œ",
                "url": "https://www.sciencecenter.go.kr",
                "type": "ê°€ì¡±í”„ë¡œê·¸ë¨"
            }
        ]
        return events
    except Exception as e:
        logger.error(f"êµ­ë¦½ê³¼ì²œê³¼í•™ê´€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return []

def crawl_regional_observatories():
    """ì§€ì—­ ì²œë¬¸ëŒ€ ì •ë³´"""
    observatories = [
        {
            "name": "ë³´í˜„ì‚°ì²œë¬¸ëŒ€",
            "title": "ë³´í˜„ì‚°ì²œë¬¸ëŒ€ ê²¬í•™í”„ë¡œê·¸ë¨",
            "date": "ë§¤ì£¼ í† ìš”ì¼ (ì˜ˆì•½ í•„ìˆ˜)",
            "location": "ê²½ë¶ ì˜ì²œì‹œ",
            "url": "https://boao.kasi.re.kr",
            "type": "ê²¬í•™"
        },
        {
            "name": "ì†Œë°±ì‚°ì²œë¬¸ëŒ€",
            "title": "ë³„ë¹›ì¶•ì œ ë° ê´€ì¸¡ì²´í—˜",
            "date": "4ì›”-10ì›” ë§¤ì£¼ í† ìš”ì¼",
            "location": "ê²½ë¶ ì˜ì£¼ì‹œ",
            "url": "http://sobaeksan.go.kr",
            "type": "ì²´í—˜"
        },
        {
            "name": "ì˜ì›”ë³„ë§ˆë¡œì²œë¬¸ëŒ€",
            "title": "ë³„ë§ˆë¡œì²œë¬¸ëŒ€ ê´€ì¸¡í”„ë¡œê·¸ë¨",
            "date": "ì—°ì¤‘ ìš´ì˜ (ë‚ ì”¨ì— ë”°ë¼ ë³€ë™)",
            "location": "ê°•ì› ì˜ì›”êµ°",
            "url": "http://www.yao.or.kr",
            "type": "ê´€ì¸¡"
        },
        {
            "name": "í™”ì²œì¡°ê²½ì² ì²œë¬¸ëŒ€",
            "title": "ë³„ë‚˜ë¼ì¶•ì œ ë° ì²œì²´ê´€ì¸¡",
            "date": "ì—¬ë¦„ì²  íŠ¹ë³„í”„ë¡œê·¸ë¨",
            "location": "ê°•ì› í™”ì²œêµ°",
            "url": "http://www.hccf.or.kr",
            "type": "ì¶•ì œ"
        }
    ]
    return observatories

def send_observatory_to_spring(event: Dict) -> bool:
    """ì²œë¬¸ëŒ€ ì¼ì •ì„ ìŠ¤í”„ë§ ì„œë²„ë¡œ ì „ì†¡"""
    from config import SPRING_SERVER_URL, REQUEST_TIMEOUT
    
    # ì²œë¬¸ëŒ€ ì¼ì • í¬ë§·íŒ…
    formatted_content = f"""ğŸ›ï¸ **{event['name']} {event['type']}**

ğŸ“… **ì¼ì •**: {event['date']}
ğŸ“ **ìœ„ì¹˜**: {event['location']}
ğŸ¯ **í”„ë¡œê·¸ë¨**: {event['title']}

---
ğŸ”— **ìì„¸í•œ ì •ë³´**: {event['url']}
ğŸ“ **ì˜ˆì•½ ë¬¸ì˜**: í•´ë‹¹ ì²œë¬¸ëŒ€ í™ˆí˜ì´ì§€ ì°¸ì¡°
ğŸ·ï¸ **ì¹´í…Œê³ ë¦¬**: ì²œë¬¸ëŒ€/ê²¬í•™"""

    payload = {
        "title": f"[{event['name']}] {event['title']}",
        "content": formatted_content,
        "type": "OBSERVATORY"
    }
    
    try:
        response = requests.post(
            f"{SPRING_SERVER_URL}/api/public/ai/news",
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=REQUEST_TIMEOUT
        )
        
        if response.status_code == 200:
            logger.info(f"ì²œë¬¸ëŒ€ ì¼ì • ì „ì†¡ ì„±ê³µ: {event['name']}")
            return True
        else:
            logger.error(f"ì²œë¬¸ëŒ€ ì¼ì • ì „ì†¡ ì‹¤íŒ¨: {event['name']}, ì‘ë‹µ: {response.status_code}")
            return False
    except Exception as e:
        logger.error(f"ì²œë¬¸ëŒ€ ì¼ì • ì „ì†¡ ì˜ˆì™¸: {event['name']}: {e}")
        return False

async def crawl_all_observatories():
    """ëª¨ë“  ì²œë¬¸ëŒ€ ì¼ì • í¬ë¡¤ë§ ë° ì „ì†¡"""
    logger.info(f"ì²œë¬¸ëŒ€ ì¼ì • í¬ë¡¤ë§ ì‹œì‘: {datetime.now()}")
    
    all_events = []
    all_events.extend(crawl_kasi_observatory())
    all_events.extend(crawl_seoul_observatory())
    all_events.extend(crawl_gwacheon_observatory())
    all_events.extend(crawl_regional_observatories())
    
    success_count = 0
    for event in all_events:
        if send_observatory_to_spring(event):
            success_count += 1
    
    logger.info(f"ì²œë¬¸ëŒ€ ì¼ì • í¬ë¡¤ë§ ì™„ë£Œ: ì´ {len(all_events)}ê°œ ì¤‘ {success_count}ê°œ ì „ì†¡ ì„±ê³µ")
    return {"total": len(all_events), "success": success_count}