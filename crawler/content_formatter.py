import re
import logging
from typing import Tuple, Optional

logger = logging.getLogger(__name__)

def clean_and_format_content(content: str) -> str:
    """ê¸°ì‚¬ ë‚´ìš©ì„ ì •ë¦¬í•˜ê³  í¬ë§·íŒ…"""
    if not content:
        return "ê¸°ì‚¬ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
    unwanted_patterns = [
        r'ì¿ í‚¤.*?ìˆ˜ë½.*?',
        r'ë‹¤ìš´ë¡œë“œ.*?MB.*?',
        r'ì†ŒìŠ¤.*?MB.*?',
        r'ì¢‹ì•„ìš”.*?ì¡°íšŒ.*?',
        r'ID.*?\d+.*?',
        r'ë¼ì´ì„¼ìŠ¤.*?í‘œì¤€.*?',
        r'YouTube.*?ì»¨íŠ¸ë¡¤.*?',
        r'ìŒì•… í´ë¦½.*?',
        r'í¬í•¨ ì½”ë“œ.*?',
        r'ìº¡ì…˜.*?ìžë§‰.*?',
        r'\d{2}/\d{2}/\d{4}.*?\d+.*?ì¡°íšŒ',
        r'00:\d{2}:\d{2}',
        r'MP4.*?\[.*?MB\]',
    ]
    
    cleaned_content = content
    for pattern in unwanted_patterns:
        cleaned_content = re.sub(pattern, '', cleaned_content, flags=re.IGNORECASE)
    
    # ì—°ì†ëœ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì •ë¦¬
    cleaned_content = re.sub(r'\s+', ' ', cleaned_content)
    cleaned_content = re.sub(r'\n\s*\n', '\n\n', cleaned_content)
    
    # ë¬¸ìž¥ ë‹¨ìœ„ë¡œ ì •ë¦¬
    sentences = [s.strip() for s in cleaned_content.split('.') if s.strip() and len(s.strip()) > 10]
    
    # ì˜ë¯¸ìžˆëŠ” ë¬¸ìž¥ë“¤ë§Œ ì„ ë³„ (ìµœëŒ€ 5ë¬¸ìž¥)
    meaningful_sentences = []
    for sentence in sentences[:8]:
        if len(sentence) > 20 and not any(word in sentence.lower() for word in 
                                        ['ì¿ í‚¤', 'youtube', 'ë‹¤ìš´ë¡œë“œ', 'ë¼ì´ì„¼ìŠ¤', 'í´ë¦½']):
            meaningful_sentences.append(sentence.strip() + '.')
    
    return ' '.join(meaningful_sentences[:5]) if meaningful_sentences else content[:500]

def extract_image_url(soup, base_url: str) -> Optional[str]:
    """ê¸°ì‚¬ì—ì„œ ëŒ€í‘œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
    try:
        # ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ì„ íƒìžë“¤
        img_selectors = [
            'meta[property="og:image"]',
            'meta[name="twitter:image"]',
            '.article-image img',
            '.post-image img',
            '.featured-image img',
            'article img',
            '.content img'
        ]
        
        for selector in img_selectors:
            img_elem = soup.select_one(selector)
            if img_elem:
                img_url = img_elem.get('content') or img_elem.get('src')
                if img_url:
                    # ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
                    if img_url.startswith('//'):
                        img_url = 'https:' + img_url
                    elif img_url.startswith('/'):
                        img_url = base_url + img_url
                    elif not img_url.startswith('http'):
                        img_url = base_url + '/' + img_url
                    
                    return img_url
        
        return None
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None

def format_news_article(title: str, content: str, source: str, url: str, image_url: Optional[str] = None) -> Tuple[str, str]:
    """ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…"""
    
    # ì œëª© ì •ë¦¬
    clean_title = title.replace('[', '').replace(']', '').strip()
    if not clean_title.startswith('['):
        clean_title = f"[{source}] {clean_title}"
    
    # ë‚´ìš© ì •ë¦¬ ë° í¬ë§·íŒ…
    clean_content = clean_and_format_content(content)
    
    # ê¸°ì‚¬ ë³¸ë¬¸ êµ¬ì„±
    formatted_content = f"""ðŸ“° **{source} ë‰´ìŠ¤**

{clean_content}

---
ðŸ”— **ì›ë¬¸ ë³´ê¸°**: {url}
ðŸ“… **ë°œí–‰**: {source}
ðŸ·ï¸ **ì¹´í…Œê³ ë¦¬**: ìš°ì£¼/ì²œë¬¸í•™"""

    # ì´ë¯¸ì§€ê°€ ìžˆìœ¼ë©´ ì¶”ê°€
    if image_url:
        formatted_content = f"""ðŸ“° **{source} ë‰´ìŠ¤**

ðŸ–¼ï¸ ![ë‰´ìŠ¤ ì´ë¯¸ì§€]({image_url})

{clean_content}

---
ðŸ”— **ì›ë¬¸ ë³´ê¸°**: {url}
ðŸ“… **ë°œí–‰**: {source}
ðŸ·ï¸ **ì¹´í…Œê³ ë¦¬**: ìš°ì£¼/ì²œë¬¸í•™"""
    
    return clean_title, formatted_content

def create_summary(content: str) -> str:
    """ê¸°ì‚¬ ë‚´ìš©ì—ì„œ ìš”ì•½ ìƒì„±"""
    sentences = [s.strip() for s in content.split('.') if s.strip() and len(s.strip()) > 20]
    
    # ì²« 2-3ë¬¸ìž¥ìœ¼ë¡œ ìš”ì•½ ìƒì„±
    summary_sentences = sentences[:3]
    summary = '. '.join(summary_sentences)
    
    if len(summary) > 200:
        summary = summary[:197] + "..."
    
    return summary + "." if summary and not summary.endswith('.') else summary