# 🚀 Byeolnight AI 크롤링 시스템 명세서

## 📋 크롤링 항목 및 스케줄

| 항목 | 수집 주기 | 수집 시간 | 대상 출처 | 중복 처리 방식 | 비고 |
|------|-----------|-----------|-----------|----------------|------|
| 📰 **우주 뉴스** | 하루 2회 | 오전 6시, 오후 12시 | • 사이언스타임즈<br>• 한국천문연구원 보도자료<br>• 동아사이언스<br>• 국립과천과학관 뉴스 | 기존 동일 제목 + 내용이면 skip 후 다시 크롤링하여 다른 뉴스 업로드.<br>**5번 반복 후 실패되면 포기** 후 해당 로그 전달 | 작성자: `newsbot` |
| 🏛️ **천문대 일정** | 하루 1회 | 오전 7시 | • 전국 20개 천문대<br>• KASI, 공립과학관, 지역천문대 | 동일한 일정 중복 체크 | 작성자: `observatorybot` |

## 🎯 게시글 카테고리

- **뉴스**: `NEWS`
- **천문대 일정**: `EVENT`

## 👤 작성자 ID 설정

- **뉴스봇**: `newsbot` - 우주 뉴스 전용
- **천문대봇**: `observatorybot` - 천문대 일정 전용

## 📊 로그 시스템

### 로그 파일 구조
```
logs/
├── crawler.log      # 일반 크롤링 로그 (10MB, 5개 파일 로테이션)
├── error.log        # 에러 전용 로그 (5MB, 3개 파일 로테이션)
└── duplicate.log    # 중복 처리 로그 (5MB, 2개 파일 로테이션)
```

### 예외 로그 기록 항목
- ❌ **크롤링 실패**: 웹사이트 접근 불가, 파싱 오류
- 🔄 **중복 판단 실패**: 서버 중복 체크 API 오류
- 📤 **게시 실패**: 스프링 서버 전송 실패
- 🔁 **재시도 실패**: 5회 재시도 후 최종 실패

## 🔄 중복 처리 로직

### 1단계: 로컬 중복 체크
- 제목 + 내용 해시값으로 중복 판단
- 메모리 내 처리된 해시 저장

### 2단계: 서버 중복 체크
- 스프링 서버 API 호출하여 중복 확인
- 중복 발견 시 다른 뉴스로 재시도

### 3단계: 재시도 로직
- 최대 5회 재시도
- 각 시도마다 로그 기록
- 최종 실패 시 에러 로그 저장

## 🌐 API 엔드포인트

### 뉴스 전송
- **엔드포인트**: `/api/public/ai/news`
- **방식**: POST
- **인증**: 불필요 (Public)

### 천문대 일정 전송
- **엔드포인트**: `/api/admin/crawler/events`
- **방식**: POST
- **인증**: API 키 필요 (`X-Crawler-API-Key`)

### 중복 체크
- **엔드포인트**: `/api/admin/crawler/check-duplicate`
- **방식**: POST
- **용도**: 서버 측 중복 확인

## 📈 모니터링 지표

### 성공률 추적
- 총 크롤링 시도 수
- 성공한 전송 수
- 중복으로 스킵된 수
- 재시도 후 성공한 수

### 에러 추적
- 크롤링 실패 횟수
- 서버 전송 실패 횟수
- 5회 재시도 후 포기한 횟수

## 🔧 설정 파일

### config.py 주요 설정
```python
# 중복 처리 설정
MAX_RETRY_COUNT = 5
DUPLICATE_CHECK_ENABLED = True

# 작성자 ID
NEWS_AUTHOR_ID = "newsbot"
OBSERVATORY_AUTHOR_ID = "observatorybot"

# 로깅 설정
LOG_FILE_MAX_SIZE = 10 * 1024 * 1024  # 10MB
LOG_BACKUP_COUNT = 5
```